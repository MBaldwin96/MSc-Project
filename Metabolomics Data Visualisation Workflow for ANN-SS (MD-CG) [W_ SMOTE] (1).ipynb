{"cells":[{"cell_type":"markdown","metadata":{"id":"Zw8UjXr4JkDS"},"source":["# **Metabolomics Data Visualisation Workflow for ANN-SS (MD-CG) [W/ SMOTE]**\n","\n","This Google Colab notebook describes the metabolomics data analysis and visualisation workflow for a 2 layer artificial neural network with layer 1 consisting of multiple neurons (n = 2 to 6) with a sigmoidal activation, and layer 2 (output layer) consisting of a single neuron with a sigmoidal activation function (ANN-SS) for a binary classification outcome.\n","\n","This computational workflow is described using a previously published LC-MS dataset by Sinclair et al. (2021). The study compared the metabolomic profiles across Parkinson's disease patients, characterised as medicated (MD; n=138) and drug-naive (DN; n=80), versus control (CG; n=56) using 8765 named metabolites. For the purpose of this computational workflow, only the MD vs CG samples were compared in a binary discriminant analysis. The deconvolved and annotated data from this study is deposited on Metabolomics Workbench (Study ID: MTBLS2266).\n","\n","This computational workflow requires a dataset to be in, or converted to, a previously described standardised Excel file format (Mendez et al. 2019). This format uses the Tidy Data Framework (Wickham, 2014), where each row represents an observation (e.g. sample) and each column represents a variable (e.g. age or metabolite). Each excel file (per study) contains two sheets; a data sheet and a peak sheet. The data sheet contains the metabolite concentration together with the metadata associated for each observation (requiring the inclusion of the columns: Idx, SampleID, and Class). The peak sheet contains the additional metadata that pertains to the metabolites in the data sheet (requiring the inclusion of the columns: Idx, Name, and Label). The standardisation of this format allows for the efficient re-use of this computational workflow.\n","\n","The steps included in this data analysis and visualisation workflow are:\n","1. Import Packages \n","2. Load Data and Peak Sheet\n","3. Data Pre-processing\n","4. Split Data into Train and Test Set\n","5. Hyperparameter Optimisation\n","6. Build Model and Evaluate\n","7. Permutation Testing\n","8. Bootstrap Resampling of the Model\n","9. "]},{"cell_type":"markdown","metadata":{"id":"AHwPOfMeJmfP"},"source":["# Section 1 - Import Packages"]},{"cell_type":"markdown","metadata":{"id":"B0rhXoCVViUq"},"source":["Certain packages need installing onto the virtual environment prior to use.\n","\n","For this computational workflow the CIMCB package was installed using pip, CIMCB requires:\n","\n","*   Python (\u003e=3.5)\n","*   Bokeh (\u003e=1.0.0)\n","*   Keras\n","*   NumPy (\u003e=1.12)\n","*   SciPy\n","*   scikit-learn\n","*   Statsmodels\n","*   TensorFlow\n","*   tqdm\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7105,"status":"ok","timestamp":1662291642215,"user":{"displayName":"Macauley Baldwin","userId":"13886190285091766632"},"user_tz":-60},"id":"jt9scofZFXrm","outputId":"b79292dd-e51e-4b65-f555-d8a3ca3564d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting cimcb\n","  Downloading cimcb-1.1.0-py3-none-any.whl (150 kB)\n","\u001b[K     |████████████████████████████████| 150 kB 7.6 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cimcb) (1.7.3)\n","Requirement already satisfied: bokeh\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cimcb) (2.3.3)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from cimcb) (2.8.2+zzzcolab20220719082949)\n","Requirement already satisfied: xlrd in /usr/local/lib/python3.7/dist-packages (from cimcb) (1.1.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from cimcb) (4.64.0)\n","Requirement already satisfied: numpy\u003e=1.12 in /usr/local/lib/python3.7/dist-packages (from cimcb) (1.21.6)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from cimcb) (0.12.2)\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from cimcb) (2.8.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from cimcb) (1.3.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from cimcb) (1.0.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from cimcb) (1.1.0)\n","Requirement already satisfied: Jinja2\u003e=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh\u003e=1.0.0-\u003ecimcb) (2.11.3)\n","Requirement already satisfied: tornado\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh\u003e=1.0.0-\u003ecimcb) (5.1.1)\n","Requirement already satisfied: packaging\u003e=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh\u003e=1.0.0-\u003ecimcb) (21.3)\n","Requirement already satisfied: pillow\u003e=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh\u003e=1.0.0-\u003ecimcb) (7.1.2)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh\u003e=1.0.0-\u003ecimcb) (4.1.1)\n","Requirement already satisfied: PyYAML\u003e=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh\u003e=1.0.0-\u003ecimcb) (6.0)\n","Requirement already satisfied: python-dateutil\u003e=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh\u003e=1.0.0-\u003ecimcb) (2.8.2)\n","Requirement already satisfied: MarkupSafe\u003e=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2\u003e=2.9-\u003ebokeh\u003e=1.0.0-\u003ecimcb) (2.0.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=16.8-\u003ebokeh\u003e=1.0.0-\u003ecimcb) (3.0.9)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil\u003e=2.1-\u003ebokeh\u003e=1.0.0-\u003ecimcb) (1.15.0)\n","Requirement already satisfied: pytz\u003e=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas-\u003ecimcb) (2022.2.1)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-\u003ecimcb) (3.1.0)\n","Requirement already satisfied: patsy\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels-\u003ecimcb) (0.5.2)\n","Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003ecimcb) (1.1.0)\n","Requirement already satisfied: grpcio\u003c2.0,\u003e=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003ecimcb) (1.47.0)\n","Requirement already satisfied: gast\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003ecimcb) (0.5.3)\n","Requirement already satisfied: wrapt\u003e=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003ecimcb) (1.14.1)\n","Requirement already satisfied: protobuf\u003c3.20,\u003e=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003ecimcb) (3.17.3)\n","Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003ecimcb) (3.3.0)\n","Requirement already satisfied: tensorflow-estimator\u003c2.9,\u003e=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003ecimcb) (2.8.0)\n","Requirement already satisfied: libclang\u003e=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003ecimcb) (14.0.6)\n","Requirement already satisfied: absl-py\u003e=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003ecimcb) (1.2.0)\n","Requirement already satisfied: flatbuffers\u003e=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003ecimcb) (2.0.7)\n","Requirement already satisfied: tensorboard\u003c2.9,\u003e=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003ecimcb) (2.8.0)\n","Requirement already satisfied: h5py\u003e=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003ecimcb) (3.1.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem\u003e=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003ecimcb) (0.26.0)\n","Requirement already satisfied: google-pasta\u003e=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003ecimcb) (0.2.0)\n","Requirement already satisfied: astunparse\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003ecimcb) (1.6.3)\n","Requirement already satisfied: keras-preprocessing\u003e=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003ecimcb) (1.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003ecimcb) (57.4.0)\n","Requirement already satisfied: wheel\u003c1.0,\u003e=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse\u003e=1.6.0-\u003etensorflow-\u003ecimcb) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py\u003e=2.9.0-\u003etensorflow-\u003ecimcb) (1.5.2)\n","Requirement already satisfied: tensorboard-data-server\u003c0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003ecimcb) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003ecimcb) (1.8.1)\n","Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003ecimcb) (1.35.0)\n","Requirement already satisfied: werkzeug\u003e=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003ecimcb) (1.0.1)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003ecimcb) (3.4.1)\n","Requirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003ecimcb) (0.4.6)\n","Requirement already satisfied: requests\u003c3,\u003e=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003ecimcb) (2.23.0)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003ecimcb) (0.2.8)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003ecimcb) (4.9)\n","Requirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003ecimcb) (4.2.4)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003ecimcb) (1.3.1)\n","Requirement already satisfied: importlib-metadata\u003e=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown\u003e=2.6.8-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003ecimcb) (4.12.0)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=4.4-\u003emarkdown\u003e=2.6.8-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003ecimcb) (3.8.1)\n","Requirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003ecimcb) (0.4.8)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003ecimcb) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003ecimcb) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003ecimcb) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003ecimcb) (1.24.3)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003ecimcb) (3.2.0)\n","Installing collected packages: cimcb\n","Successfully installed cimcb-1.1.0\n"]}],"source":["pip install cimcb"]},{"cell_type":"markdown","metadata":{"id":"ke-ci_TTVwui"},"source":["To use tools that extend beyond the basic functionalities of Python programming, packages must first be imported to enable their use in each Google Colab environment. Each package is a container of modules.\n","\n","For this computational workflow, the following packages were used:\n","\n","\n","*   numpy: A fundamental package for scientific computing with Python, primarly used for the manipulation of arrays\n","*   pandas: A fundamental package for data analysis and manipulation\n","*   cimcb: A package for the statistical analysis of untargeted and targeted metabolomics data\n","*   matplotlib.pyplot: A package mainly used for interactive plots and simple cases of programmatic plot generation\n","*   seaborn: A package that provides a high-level interface for drawing attractive and informative statistical graphics\n","*   sklearn: A fundamental package containing tools for machine learning\n","  *   train_test_split: A method to split arrays into training and test subsets\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":327,"status":"ok","timestamp":1662291860298,"user":{"displayName":"Macauley Baldwin","userId":"13886190285091766632"},"user_tz":-60},"id":"nDsKYVXmI6KJ","outputId":"42d70911-a71c-4057-920c-838e1a404e65"},"outputs":[{"name":"stdout","output_type":"stream","text":["All packages successfully loaded\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.model_selection import train_test_split\n","\n","import cimcb as cb\n","\n","print('All packages successfully loaded')"]},{"cell_type":"markdown","metadata":{"id":"vfs9sQc2VhI4"},"source":["In order to  reproducibility of the workflow, random seeds are set.\n","\n","*   seed_split: Seed the generator using an integer value e.g. 42 (default = None ; no seed set)\n","\n","This seed is used to mainatin duplicability in the way the data is divided when the train and test set are generated.\n","\n","*  seed_init: seed the generator using an integer value e.g. 42 (default = None ; no seed set)\n","\n","This seed is used to maintain duplicability in the way the intial weights are drawn from a truncated normal distribution when the neural network is first compiled."]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":234,"status":"ok","timestamp":1662291866522,"user":{"displayName":"Macauley Baldwin","userId":"13886190285091766632"},"user_tz":-60},"id":"p0p-yhcuOOA4"},"outputs":[],"source":["seed_split = 100\n","seed_init = 4\n","# seed_split = None\n","# seed_init = None"]},{"cell_type":"markdown","metadata":{"id":"AbK7gAMDJzCZ"},"source":["# Section 2 - Load Data \u0026 Peak Sheet"]},{"cell_type":"markdown","metadata":{"id":"o-rIer__s2BE"},"source":["To upload the dataset to the Google Colab notebook environment, an upload widget was used."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":39,"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","headers":[["content-type","application/javascript"]],"ok":true,"status":200,"status_text":""}}},"id":"WTO9CmV_LS-u"},"outputs":[{"data":{"text/html":["\n","     \u003cinput type=\"file\" id=\"files-77aae0b0-7e79-4c26-aced-799ea2c1ff6b\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" /\u003e\n","     \u003coutput id=\"result-77aae0b0-7e79-4c26-aced-799ea2c1ff6b\"\u003e\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      \u003c/output\u003e\n","      \u003cscript src=\"/nbextensions/google.colab/files.js\"\u003e\u003c/script\u003e "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["from google.colab import files\n","\n","uploaded = files.upload()"]},{"cell_type":"markdown","metadata":{"id":"iTndIMXIs9ZM"},"source":["The helper function load_dataXL loads the two data sheets from the Excel file 'Data and Peak sheet_Test.xlsx'. Provided the dataset adheres to the standardised TidyData framework format, load_dataXL() outputs the data sheets from the uploaded Excel file as individual Pandas DataFrames."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FCw79GeMLXdT"},"outputs":[],"source":["# The path to the input file (Excel spreadsheet)\n","filename = 'Data and Peak sheet_Test.xlsx'\n","\n","# Load Peak and Data tables into two variables\n","dataTable, peakTable = cb.utils.load_dataXL(filename, DataSheet='Data', PeakSheet='Peaks')"]},{"cell_type":"markdown","metadata":{"id":"CUlOuA5rJ45H"},"source":["# Section 3 - Data Pre-processing"]},{"cell_type":"markdown","metadata":{"id":"Q7AcCYUmy345"},"source":["**Section 3.1 - Data Cleaning**\n","\n","According to Broadhurst (2019), it is best practice to access the quality of the data and refine the dataset by removing those metabolites that lack reporducible measurements. The QC-RSD and percentage of missing values has been calculated and are included in the peakTable DataFrame. Using those values, we remove all metabolomic features that do not meet the following criteria:\n","\n","*   QC-RSD less than 20%\n","* Fewer than 10% of values are missing\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w3MQ5d-rLfNZ"},"outputs":[],"source":["# Clean PeakTable\n","RSD = peakTable['QC_RSD']   \n","percMiss = peakTable['Perc_missing']  \n","peakTableClean = peakTable[(RSD \u003c 20) \u0026 (percMiss \u003c 10)]   \n","peakList = peakTableClean['Name']  \n","\n","print(\"Number of peaks remaining: {}\".format(len(peakTableClean)))"]},{"cell_type":"markdown","metadata":{"id":"lwOSl3IT1EFl"},"source":["**Section 3.2 - Extract X and Y**\n","\n","As previously mentioned, this workflow is performing binary classification of the classes MD vs CG. The X matrix of metabolite concentrations and Y vector of classification labels (\"MD\"=0 and \"CG\"=1) are extracted through the following steps:\n","\n","1.   Create a subset of the dataTable called dataTable1, containing samples in the Class \"MD\" or \"CG\"\n","2.   Use the peakList variable to hold the names of the metabolites to be used \n","3.   Extract all the applicable columns, using peakList, from dataTable1 and place in matrix X\n","4.   Set Y to the list of binary outcomes from the \"Class\" column from dataTable1\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HglKIIiVLng5"},"outputs":[],"source":["# Extract PeakList\n","dataTable1 = dataTable[(dataTable.Class == \"MD\") | (dataTable.Class == \"CG\")]  # Reduce data table only to MD and CG class members\n","pos_outcome = \"CG\"\n","\n","dataTable1['Class'] = [0 if x == 'MD' else 1 for x in dataTable1['Class']]\n","\n","to_drop = ['Idx', 'SampleID', 'SampleType']\n","dataTable1.drop(to_drop, axis=1, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8w8TRXi4MBAc"},"outputs":[],"source":["peaklist = peakTableClean['Name']          \n","X = dataTable1[peaklist]\n","\n","merged = pd.concat([dataTable1['Class'], X], axis=1)\n","\n","merged.reset_index()"]},{"cell_type":"markdown","metadata":{"id":"QsivpJOYaW3t"},"source":["**Section 3.3 - Transform and Scale Data**\n","\n","The MinMaxScaler() method is used to scale all columns that contain values larger than 1, to [0,1] range. This makes the values more manageable when creating and evaluating of the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"op7stgQ_N2Mr"},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","# Scale only columns that have values greater than 1\n","to_scale = [col for col in X.columns if X[col].max() \u003e 1]\n","mms = MinMaxScaler()\n","scaled = mms.fit_transform(merged[to_scale])\n","scaled = pd.DataFrame(scaled, columns=to_scale)\n","\n","# Replace original columns with scaled ones\n","for col in scaled:\n","    merged.reset_index()[col] = scaled[col]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mfmh2xgCMNTH"},"outputs":[],"source":["y1 = merged['Class']\n","merged1 = pd.concat([y1.reset_index()['Class'], scaled], axis=1)\n","\n","display(merged1)\n","\n","from sklearn.model_selection import train_test_split\n","\n","X = merged1.drop('Class', axis=1)\n","y = merged1['Class']\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.33, random_state=42\n",")\n","\n","print(f'''% Positive class in Train = {np.round(y_train.value_counts(normalize=True)[1] * 100, 2)}\n","% Positive class in Test  = {np.round(y_test.value_counts(normalize=True)[1] * 100, 2)}''')"]},{"cell_type":"markdown","metadata":{"id":"F5RPKs6ZaG9x"},"source":["**Section 3.4 - Data Balancing with Missing Values Imputed**\n","\n","The Synthetic Minority Oversampling Technique (SMOTE) is a statisical method that balances the amount of samples in a dataset by oversampling the minority class. Empty cells are imputed using the .nan_to_num() method."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QctcJ7ExMNrm"},"outputs":[],"source":["from imblearn.over_sampling import SMOTE \n","\n","sm = SMOTE(random_state=42)\n","\n","x = np.nan_to_num(X)\n","Y = np.nan_to_num(y)\n","\n","X_sm, y_sm = sm.fit_resample(x, Y)\n","\n","print(f'''Shape of X before SMOTE: {X.shape}\n","Shape of X after SMOTE: {X_sm.shape}''')\n","\n","print('\\nBalance of positive and negative classes (%):')\n","pd.Series(y_sm).value_counts(normalize=True) * 100"]},{"cell_type":"markdown","metadata":{"id":"dkjpB7ICJ8an"},"source":["# Section 4 - Split Data in Train and Test Set"]},{"cell_type":"markdown","metadata":{"id":"LVRbehcIbCIb"},"source":["Using the train_test_split method, the balanced X and Y data is divided into train (2/3) and test (1/3) sets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6YrmQW2bMYfT"},"outputs":[],"source":["# Optional: Save Class Labels for Figure Legends\n","Class = merged1.Class\n","\n","# Split Data into Train (2/3rd) and Test (1/3rd)\n","XTrain, XTest, YTrain, YTest = train_test_split(X_sm,\n","                                                y_sm,\n","                                                test_size=1/3,\n","                                                random_state=seed_split)"]},{"cell_type":"markdown","metadata":{"id":"YrYBPUCiKATD"},"source":["# Section 5 - Hyperparameter Optimisation"]},{"cell_type":"markdown","metadata":{"id":"JhXQxlI6bDkm"},"source":["**Section 5.1 - k-fold Cross-Validation**\n","\n","k-fold cross-validation (k=5) is carried out using the CIMCB helper function cb.cross_val.kfold(). This is applied to a set of ANN-SS models with number of neurons ranging from 1 - 6, and a learning rate ranging from 0.01 - 0.05."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NrZZU_2BNAT_"},"outputs":[],"source":["# Parameter Dictionary\n","lr = [0.01,0.02,0.03,0.04,0.05]\n","neurons = [2, 3, 4, 5, 6]\n","\n","param_dict = dict(learning_rate=lr,\n","                  n_neurons=neurons,\n","                  epochs=400,\n","                  momentum=0.5,\n","                  decay=0,\n","                  loss='binary_crossentropy')\n","\n","# Initialise\n","cv = cb.cross_val.kfold(model=cb.model.NN_SigmoidSigmoid,\n","                                X=XTrain,\n","                                Y=YTrain,\n","                                param_dict=param_dict,\n","                                folds=5,\n","                                n_mc=10)\n","\n","# Run \n","cv.run()"]},{"cell_type":"markdown","metadata":{"id":"-j_OCwB2bMau"},"source":["**Section 5.2 - Plot R^2 and Q^2**\n","\n","When displaying the R^2 and Q^2 statistics, there are six plots used. From left to right, top to bottom:\n","\n","1. Heatmap of R^2\n","2. Heatmap of Q^2\n","3. Heatmap of 1 - |R^2 - Q^2|\n","4. |R^2 - Q^2| vs. Q^2\n","5. R^2 \u0026 Q^2 vs. learning rate\n","6. R^2 \u0026 Q^2 vs. number of neurons\n","\n","The AUC metric portrays the predictability of the model as area under the ROC curve (AUC), AUC(full), and AUC(cv). It is a non-parametric alternative to R^2 and Q^2."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nFfXQyULtZxb"},"outputs":[],"source":["cv.plot(metric='auc', ci=95)\n","cv.plot(metric='r2q2', ci=95)"]},{"cell_type":"markdown","metadata":{"id":"fUtzgdV8bOuZ"},"source":["**Section 5.3 - Plot Latent Projections: Full and CV**\n","\n","The method .plot_projections() displays n x n grid of plots, where n is the different number of neurons in the hidden layer being analysed. The types of plot are:\n","\n","*   Score plots\n","*   Distribution plots\n","*   Receiver operating characteristic (ROC) curves\n","\n","A score plot is produced for each combination of two neurons. Within each score plot the entire score is included, presented as circles, the CV scores, presented as crosses and coloured by group, and the 95% confidence intervals, presented as solid line for full scores and a dashed line for the CV scores. The orthagonal line is displayed as a solid grey line, and the optimal line of seperation as a dashed grey line.\n","\n","For each neuron a distribution plot is produced. These display the full and CV scores for each group, using kernel density estimation to calculate each distribution.\n","\n","As with the score plots, the ROC curves produce a plot for each combination of two neurons. The discrimination is determined by the optimal seperation between the two specific neurons being interrogated. Each ROC curve is comprised of a cruve for the full model (green), a curve for the CV model (yellow) with 95% confidence intervals, and the distribution line is presented as a dashed black line."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mIX6LBzg5HLj"},"outputs":[],"source":["cv.plot_projections()"]},{"cell_type":"markdown","metadata":{"id":"lS_nszOhKHtz"},"source":["# Section 6 - Build Model and Evaluate"]},{"cell_type":"markdown","metadata":{"id":"jgdv2GeGbRLb"},"source":["Using the optimal hyperparameter values, identified in Section 5, an ANN-SS model is created and intialised. The model is then trained, where XTrain is the X matrix and YTrain is the Y vector, and tested, where XTest is the X matrix and YTest is y vector, and returns the Y predicted value YPredTest.\n","\n","The .evaluate() method uses the train and test set to evaluate the predictability of the model. Three plots are produced:\n","\n","1.   Violin plot\n","2.   Distribution plot\n","3.   ROC curve\n","\n","\"The violin plots show the predicted score for the train and test (by group). The distribution plot shows the probability density function of the predicted scores for the train and test (by group). The ROC curve shows the ROC curve for the train (green) and test (yellow).\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JbP7kPBP5Sr-"},"outputs":[],"source":["# Build Model\n","model = cb.model.NN_LogitLogit(learning_rate=0.04,\n","                                   n_neurons=5,\n","                                   epochs=75,\n","                                   momentum=0.5,\n","                                   decay=0,\n","                                   loss='binary_crossentropy')\n","YPredTrain = model.train(XTrain, YTrain)\n","YPredTest = model.test(XTest)\n","\n","# Put YTrain and YPredTrain in a List\n","EvalTrain = [YTrain, YPredTrain]\n","\n","# Put YTest and YPrestTest in a List\n","EvalTest = [YTest, YPredTest]\n","\n","\n","# Evaluate Model (include Test Dataset)\n","model.evaluate(testset=EvalTest)"]},{"cell_type":"markdown","metadata":{"id":"JRkOOLgsKM_0"},"source":["# Section 7 - Permuatation Test"]},{"cell_type":"markdown","metadata":{"id":"SeflZ9cybS4y"},"source":["After the model has been trained, permutation testing can be performed to access the reliability of the model. The .permutation_test() method randomises the X matrix, whilst the Y vector remains fixed and is then trained and tested on the randomised data. This is repeated 100 times to produce a more reliable assessment of the distribution of the model.\n","\n","The method produces two plots:\n","\n","*   R^2 \u0026 Q^2 against the correlation of permuted data against original data\n","*   Probability densities for R^2 \u0026 Q^2\n","\n","For datasets that contains metabolomic features with no meaningful contribution towards the classification we would expect R^2 \u0026 Q^2 values significantly lower than the values from a dataset that contained features with a meaningful contribution.  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5gemI3j5iKL"},"outputs":[],"source":["model.permutation_test(nperm=100)"]},{"cell_type":"markdown","metadata":{"id":"l4NvVrb4gJ91"},"source":["# Section 8 - Binary Cross-Entropy Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNB9RB3VPjau"},"outputs":[],"source":["display(XTrain)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bOsEKG6nPjhM"},"outputs":[],"source":["display(YTrain)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lrf5bYAsPjkk"},"outputs":[],"source":["display(XTest)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NYXnYqNePjns"},"outputs":[],"source":["display(YTest)"]},{"cell_type":"markdown","metadata":{"id":"Q2JIJkyhgzg3"},"source":["**BINARY CROSS-ENTROPY LOSS**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QIlZwHE9gQHy"},"outputs":[],"source":["\t\n","# mlp for the circles problem with cross entropy loss\n","from sklearn.datasets import make_circles\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from tensorflow.keras.optimizers import SGD\n","from matplotlib import pyplot\n","\n","# define model\n","model = Sequential()\n","model.add(Dense(50, input_dim=2259, activation='relu', kernel_initializer='he_uniform'))\n","model.add(Dense(1, activation='sigmoid'))\n","opt = SGD(lr=0.04, momentum=0.5)\n","model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","\n","# fit model\n","history = model.fit(XTrain, YTrain, validation_data=(XTest, YTest), epochs=75, verbose=0)\n","\n","# evaluate the model\n","_, train_acc = model.evaluate(XTrain, YTrain, verbose=0)\n","_, test_acc = model.evaluate(XTest, YTest, verbose=0)\n","print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n","\n","# plot loss during training\n","pyplot.subplot(211)\n","pyplot.title('Loss')\n","pyplot.plot(history.history['loss'], label='train')\n","pyplot.plot(history.history['val_loss'], label='test')\n","pyplot.legend()\n","\n","# plot accuracy during training\n","pyplot.subplot(212)\n","pyplot.title('Accuracy')\n","pyplot.plot(history.history['accuracy'], label='train')\n","pyplot.plot(history.history['val_accuracy'], label='test')\n","pyplot.legend()\n","pyplot.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOpXCGtzH/SXnpBOKWy8zo4","collapsed_sections":[],"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}